{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Assignment\n",
    "\n",
    "_MkKinney 6.1_\n",
    "\n",
    "This week has been all about getting information off the internet both in structured data formats (CSV, JSON, etc) as well as HTML.  For these exercises, we're going to use two practical examples of fetching data from web pages to show how to use Pandas and BeautifulSoup to extract structured information from the web.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.1 Parsing a list in HTML\n",
    "\n",
    "Go to the Banner Health Price Transparency Page: https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\n",
    "\n",
    "Notice that there is a list of hospitals and the city they are in.  We want to parse the underlying HTML to create a list of all the hospitals along with which city they're in.\n",
    "\n",
    "```json\n",
    "[\n",
    "    [\"Banner - University Medical Center Phoenix\", \"Arizona\"],\n",
    "    [\"Banner - University Medical Center South \", \"Arizona\"],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "To examine the underlying HTML code, you can use Chrome, right-click, and choose **Inspect**.\n",
    "\n",
    "For reference, the documentation for BeautifulSoup is here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a function called **parse_banner(url)** that takes as it's one parameter the URL of the webpage to be parsed for links.  Make sure you include docstrings and a good test case using hte URL provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def parse_banner(url):\n",
    "    \n",
    "    \"\"\"(url) -> string\n",
    "    This function returns an array of 2 element long arrays.\n",
    "    Each element is a \"hospital name\" anda state.\n",
    "    \n",
    "    >>> parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "    [['Banner - University Medical Center Phoenix', 'Arizona'], ['Banner - University Medical Center South\\xa0', 'Arizona'], ['Banner - University Medical Center Tucson', 'Arizona'], ['Banner Baywood Medical Center\\xa0', 'Arizona'], ['Banner Behavioral Health Hospital', 'Arizona'], ['Banner Boswell Medical Center', 'Arizona'], ['Banner Casa Grande Medical Center', 'Arizona'], ['Banner Del E. Webb Medical Center', 'Arizona'], [\"Banner Desert Medical Center/Cardon Children's Medical Center\\xa0\\xa0\", 'Arizona'], ['Banner Estrella Medical Center', 'Arizona'], ['Banner Gateway Medical Center/Banner MD Anderson Cancer Center', 'Arizona'], ['Banner Goldfield Medical Center\\xa0\\xa0', 'Arizona'], ['Banner Heart Hospital', 'Arizona'], ['Banner Ironwood Medical Center', 'Arizona'], ['Banner Ocotillo Medical Center', 'Arizona'], ['Banner Payson Medical Center', 'Arizona'], ['Banner Rehabilitation Hospitals', 'Arizona'], ['Banner Thunderbird Medical Center', 'Arizona'], ['Page Hospital', 'Arizona'], ['Banner Lassen Medical Center', 'California'], ['Banner Fort Collins Medical Center', 'Colorado'], ['McKee Medical Center', 'Colorado'], ['North Colorado Medical Center', 'Colorado'], ['Sterling Regional Medical Center', 'Colorado'], ['East Morgan County Hospital', 'Colorado'], ['Ogallala Community Hospital', 'Nebraska'], ['Banner Churchill Community Hospital', 'Nevada'], ['Banner Wyoming Medical Center\\xa0Central Campus', 'Wyoming'], ['Banner Wyoming Medical Center East Campus', 'Wyoming'], ['Community Hospital', 'Wyoming'], ['Washakie Medical Center', 'Wyoming'], ['Platte County Memorial Hospital', 'Wyoming']]\n",
    "    \"\"\"\n",
    "    returnlist = []\n",
    "    # Note that you'll need to fetch the data using the following syntax to include headers\n",
    "    # that make the web server think you're a real web browser.\n",
    "    headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    for link in soup.find_all('p'):\n",
    "        if (link.strong):\n",
    "            state = link.strong.text\n",
    "            for sib in link.find_next_sibling(\"ul\"):\n",
    "                if sib.name == \"li\":\n",
    "                    hospital = sib.text\n",
    "                    returnlist.append([hospital, state])\n",
    "    return returnlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
      "Expecting:\n",
      "    [['Banner - University Medical Center Phoenix', 'Arizona'], ['Banner - University Medical Center South ', 'Arizona'], ['Banner - University Medical Center Tucson', 'Arizona'], ['Banner Baywood Medical Center ', 'Arizona'], ['Banner Behavioral Health Hospital', 'Arizona'], ['Banner Boswell Medical Center', 'Arizona'], ['Banner Casa Grande Medical Center', 'Arizona'], ['Banner Del E. Webb Medical Center', 'Arizona'], [\"Banner Desert Medical Center/Cardon Children's Medical Center  \", 'Arizona'], ['Banner Estrella Medical Center', 'Arizona'], ['Banner Gateway Medical Center/Banner MD Anderson Cancer Center', 'Arizona'], ['Banner Goldfield Medical Center  ', 'Arizona'], ['Banner Heart Hospital', 'Arizona'], ['Banner Ironwood Medical Center', 'Arizona'], ['Banner Ocotillo Medical Center', 'Arizona'], ['Banner Payson Medical Center', 'Arizona'], ['Banner Rehabilitation Hospitals', 'Arizona'], ['Banner Thunderbird Medical Center', 'Arizona'], ['Page Hospital', 'Arizona'], ['Banner Lassen Medical Center', 'California'], ['Banner Fort Collins Medical Center', 'Colorado'], ['McKee Medical Center', 'Colorado'], ['North Colorado Medical Center', 'Colorado'], ['Sterling Regional Medical Center', 'Colorado'], ['East Morgan County Hospital', 'Colorado'], ['Ogallala Community Hospital', 'Nebraska'], ['Banner Churchill Community Hospital', 'Nevada'], ['Banner Wyoming Medical Center Central Campus', 'Wyoming'], ['Banner Wyoming Medical Center East Campus', 'Wyoming'], ['Community Hospital', 'Wyoming'], ['Washakie Medical Center', 'Wyoming'], ['Platte County Memorial Hospital', 'Wyoming']]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(parse_banner, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "banner = parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "assert len(banner)==32, 'Length of result should have been 38, but {} returned.'.format(len(banner))\n",
    "assert banner[0][1]=='Arizona', 'Wrong data found in the first result item: {}'.format(banner[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 33.2 Using a REST API (from GitHub.com)\n",
    "\n",
    "Many websites provide something called a REST API to access information from their site programatically, rather than relying on HTML.  One example is GitHub.com, whose API allows you do to things like \"list all the public repositories for a user.\"\n",
    "\n",
    "The documentation for GitHub.com's REST API can be found here: https://docs.github.com/en/rest/guides/getting-started-with-the-rest-api\n",
    "\n",
    "Create a function called **repo_summary(user)** that takes a GitHub.com user name as it's parameter and retrieves a list of all the repositories you can see for that user.  The specific documentation for the this kind of request can be found here: https://docs.github.com/en/rest/reference/repos#list-repositories-for-a-user. Make sure your function is well documented with a docstring and includes a simple test to verify that you get back 12 repositories when querying for the repositories for user **paulboal**.\n",
    "\n",
    "I've provided a related example to help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This information is about paulboal. His website is www.amitechsolutions.com.\n"
     ]
    }
   ],
   "source": [
    "# Example -- this example of code shows how to get basic information on the user paulboal\n",
    "# For your solution, make sure you meet the requirements in the instructions above.\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://api.github.com/users/paulboal')\n",
    "data = response.json()\n",
    "\n",
    "print('This information is about {}. His website is {}.'.format(data.get('login'), data.get('blog')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_array(array):\n",
    "    \"\"\"(url) -> string (github user name)\n",
    "    This function returns an array of public repository names.\n",
    "    \n",
    "    >>> print_array([{\"a\", 1}, {\"b\",2}])\n",
    "    {1, 'a'}\n",
    "    {2, 'b'}\n",
    "\n",
    "    \"\"\"   \n",
    "    for i in array:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    print_array([{\"a\", 1}, {\"b\",2}])\n",
      "Expecting:\n",
      "    {1, 'a'}\n",
      "    {2, 'b'}\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(print_array, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "# Example -- this example of code shows how to get basic information on the user paulboal\n",
    "# For your solution, make sure you meet the requirements in the instructions above.\n",
    "\n",
    "def repo_summary(github_user):\n",
    "    \"\"\"(url) -> string (github user name)\n",
    "    This function returns an array of public repository names.\n",
    "    \n",
    "    >>> repo_summary('paulboal')\n",
    "    [{'url': 'https://github.com/paulboal/ajaxterm', 'desc': 'Patched copy of Ajaxterm that allows connecting to remote SSH servers'}, {'url': 'https://github.com/paulboal/cms_hospital_compare', 'desc': 'Hadoop Sandbox demo with CMS Hospital Compare data'}, {'url': 'https://github.com/paulboal/collibra-scripts', 'desc': 'Scripts (mostly Python) for automating tasks with the Collibra API'}, {'url': 'https://github.com/paulboal/coronadatascraper', 'desc': 'COVID-19 Coronavirus data scraped from government and curated data sources.'}, {'url': 'https://github.com/paulboal/hadoop-heuristicsminer', 'desc': 'The project implements the HeuristicsMiner process mining algorithm in Hadoop MapReduce.  See the README for additional information.'}, {'url': 'https://github.com/paulboal/hds5210-2021', 'desc': 'Course content for HDS5210 Spring 2021'}, {'url': 'https://github.com/paulboal/hds5210-2022', 'desc': 'Main class repository for HDS5210-2022'}, {'url': 'https://github.com/paulboal/jupyterhub-nbgrader', 'desc': 'Reference deployment of JupyterHub with docker'}, {'url': 'https://github.com/paulboal/nppes_demo', 'desc': 'Loading NPPES data into Hadoop for search'}, {'url': 'https://github.com/paulboal/pexpect-curses', 'desc': 'An extension to pexpect (Python expect) that allows scraping curses screens using the vt102 module.'}, {'url': 'https://github.com/paulboal/scm-products', 'desc': 'Supply Chain Project'}, {'url': 'https://github.com/paulboal/tdwi-accelerate-2017-python', 'desc': 'Code and materials for the TDWI Accelerate 2017 Python Quick Camp'}]\n",
    "    \"\"\"  \n",
    "    url = \"https://api.github.com/users/\" + github_user + \"/repos\" \n",
    "    results = []\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    #print(json.dumps(data, indent = 4))\n",
    "    #print('This information is about {}. His website is {}.'.format(data.get('login'), data.get('blog')))\n",
    "    for repo in data:\n",
    "        repo_url = repo.get('html_url')\n",
    "        desc = repo.get('description')\n",
    "        results.append({'url':repo_url, 'desc': desc})\n",
    "    return results\n",
    "    \n",
    "#print_array(repo_summary(\"paulboal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    repo_summary('paulboal')\n",
      "Expecting:\n",
      "    [{'url': 'https://github.com/paulboal/ajaxterm', 'desc': 'Patched copy of Ajaxterm that allows connecting to remote SSH servers'}, {'url': 'https://github.com/paulboal/cms_hospital_compare', 'desc': 'Hadoop Sandbox demo with CMS Hospital Compare data'}, {'url': 'https://github.com/paulboal/collibra-scripts', 'desc': 'Scripts (mostly Python) for automating tasks with the Collibra API'}, {'url': 'https://github.com/paulboal/coronadatascraper', 'desc': 'COVID-19 Coronavirus data scraped from government and curated data sources.'}, {'url': 'https://github.com/paulboal/hadoop-heuristicsminer', 'desc': 'The project implements the HeuristicsMiner process mining algorithm in Hadoop MapReduce.  See the README for additional information.'}, {'url': 'https://github.com/paulboal/hds5210-2021', 'desc': 'Course content for HDS5210 Spring 2021'}, {'url': 'https://github.com/paulboal/hds5210-2022', 'desc': 'Main class repository for HDS5210-2022'}, {'url': 'https://github.com/paulboal/jupyterhub-nbgrader', 'desc': 'Reference deployment of JupyterHub with docker'}, {'url': 'https://github.com/paulboal/nppes_demo', 'desc': 'Loading NPPES data into Hadoop for search'}, {'url': 'https://github.com/paulboal/pexpect-curses', 'desc': 'An extension to pexpect (Python expect) that allows scraping curses screens using the vt102 module.'}, {'url': 'https://github.com/paulboal/scm-products', 'desc': 'Supply Chain Project'}, {'url': 'https://github.com/paulboal/tdwi-accelerate-2017-python', 'desc': 'Code and materials for the TDWI Accelerate 2017 Python Quick Camp'}]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(repo_summary, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    repo_summary('paulboal')\n",
      "Expecting:\n",
      "    [{'url': 'https://github.com/paulboal/ajaxterm', 'desc': 'Patched copy of Ajaxterm that allows connecting to remote SSH servers'}, {'url': 'https://github.com/paulboal/cms_hospital_compare', 'desc': 'Hadoop Sandbox demo with CMS Hospital Compare data'}, {'url': 'https://github.com/paulboal/collibra-scripts', 'desc': 'Scripts (mostly Python) for automating tasks with the Collibra API'}, {'url': 'https://github.com/paulboal/coronadatascraper', 'desc': 'COVID-19 Coronavirus data scraped from government and curated data sources.'}, {'url': 'https://github.com/paulboal/hadoop-heuristicsminer', 'desc': 'The project implements the HeuristicsMiner process mining algorithm in Hadoop MapReduce.  See the README for additional information.'}, {'url': 'https://github.com/paulboal/hds5210-2021', 'desc': 'Course content for HDS5210 Spring 2021'}, {'url': 'https://github.com/paulboal/hds5210-2022', 'desc': 'Main class repository for HDS5210-2022'}, {'url': 'https://github.com/paulboal/jupyterhub-nbgrader', 'desc': 'Reference deployment of JupyterHub with docker'}, {'url': 'https://github.com/paulboal/nppes_demo', 'desc': 'Loading NPPES data into Hadoop for search'}, {'url': 'https://github.com/paulboal/pexpect-curses', 'desc': 'An extension to pexpect (Python expect) that allows scraping curses screens using the vt102 module.'}, {'url': 'https://github.com/paulboal/scm-products', 'desc': 'Supply Chain Project'}, {'url': 'https://github.com/paulboal/tdwi-accelerate-2017-python', 'desc': 'Code and materials for the TDWI Accelerate 2017 Python Quick Camp'}]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(repo_summary, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = repo_summary('paulboal')\n",
    "assert len(repos)==12, 'Expecing 12, but {} were found'.format(len(repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 33.3 Find Something of Your Own\n",
    "\n",
    "Do some web searches and find an HTML page with some data that is interesting to something you're studying.  You can extract and parse that information using either BeautifulSoup or Pandas.  If you're using Pandas, then do something interesting to format and structure your data.  If you're using BeautifulSoup, you'll just need to do the work of parsing the data out of HTML -- that's hard enough!\n",
    "\n",
    "You don't need to build this as a function.  Just use notebook cells as I've done above.  You will be graded based on _style_.  Use variable names that make sense for your problem / solution. Cleanup anything you don't need before you submit your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next section obtains a specific table from a wikipedia page of Texas -  min/max of the daily temperature from the major cities in Texas\n",
    "#### 1. Pick on the August and Janurary temperature n Fahrenheit\n",
    "#### 2. List the important cities \n",
    "#### 3. Split up the columm into 2 columns \"max and min\"\n",
    "#### 4. Find the city with the max daily temperature and the one with the min temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Location      8 non-null      object\n",
      " 1   August (°F)   8 non-null      object\n",
      " 2   August (°C)   8 non-null      object\n",
      " 3   January (°F)  8 non-null      object\n",
      " 4   January (°C)  8 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>August (°F)</th>\n",
       "      <th>August (°C)</th>\n",
       "      <th>January (°F)</th>\n",
       "      <th>January (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston</td>\n",
       "      <td>94/75</td>\n",
       "      <td>34/24</td>\n",
       "      <td>63/54</td>\n",
       "      <td>17/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>96/74</td>\n",
       "      <td>35/23</td>\n",
       "      <td>63/40</td>\n",
       "      <td>17/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>96/77</td>\n",
       "      <td>36/25</td>\n",
       "      <td>57/37</td>\n",
       "      <td>16/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin</td>\n",
       "      <td>97/74</td>\n",
       "      <td>36/23</td>\n",
       "      <td>61/45</td>\n",
       "      <td>16/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>92/67</td>\n",
       "      <td>33/21</td>\n",
       "      <td>57/32</td>\n",
       "      <td>14/0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>100/77</td>\n",
       "      <td>37/25</td>\n",
       "      <td>67/46</td>\n",
       "      <td>19/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amarillo</td>\n",
       "      <td>89/64</td>\n",
       "      <td>32/18</td>\n",
       "      <td>50/23</td>\n",
       "      <td>10/−4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brownsville</td>\n",
       "      <td>94/76</td>\n",
       "      <td>34/24</td>\n",
       "      <td>70/51</td>\n",
       "      <td>21/11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location August (°F) August (°C) January (°F) January (°C)\n",
       "0      Houston       94/75       34/24        63/54        17/12\n",
       "1  San Antonio       96/74       35/23        63/40         17/5\n",
       "2       Dallas       96/77       36/25        57/37         16/3\n",
       "3       Austin       97/74       36/23        61/45         16/5\n",
       "4      El Paso       92/67       33/21        57/32         14/0\n",
       "5       Laredo      100/77       37/25        67/46         19/7\n",
       "6     Amarillo       89/64       32/18        50/23        10/−4\n",
       "7  Brownsville       94/76       34/24        70/51        21/11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/Texas', match = \"Average daily maximum and minimum temperatures for selected cities in Texas\")\n",
    "txinfo = dfs[0]\n",
    "txinfo.info()\n",
    "txinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dropping the columns with the Celsius Info\n",
      "----------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Location      8 non-null      object\n",
      " 1   August (°F)   8 non-null      object\n",
      " 2   January (°F)  8 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 320.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"1. Dropping the columns with the Celsius Info\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "# Drop 2 columns (celsius info)\n",
    "txinfo.drop('January (°C)', axis = 1, inplace = True)\n",
    "txinfo.drop('August (°C)', axis = 1, inplace = True)\n",
    "txinfo.info()\n",
    "type(txinfo['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Important Cities\n",
      "----------------------------------------------------------------------\n",
      "0        Houston\n",
      "1    San Antonio\n",
      "2         Dallas\n",
      "3         Austin\n",
      "4        El Paso\n",
      "5         Laredo\n",
      "6       Amarillo\n",
      "7    Brownsville\n",
      "Name: Location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Important Cities\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(txinfo['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Split a column by the / delimiter for January and August, drop some columns, print the table \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"3. Split a column by the / delimiter for January and August, drop some columns, print the table \")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "txinfo[['January max (F)', 'January min (F)']] = txinfo['January (°F)'].str.split('/', expand=True)\n",
    "txinfo[['August max (F)', 'August min (F)']] = txinfo['August (°F)'].str.split('/', expand=True)\n",
    "txinfo.drop('January (°F)', axis = 1, inplace = True)\n",
    "txinfo.drop('August (°F)', axis = 1, inplace = True)\n",
    "\n",
    "# Change a few data types to integer \n",
    "\n",
    "txinfo[\"January max (F)\"] = pd.to_numeric(txinfo[\"January max (F)\"])\n",
    "txinfo[\"January min (F)\"] = pd.to_numeric(txinfo[\"January min (F)\"])\n",
    "txinfo[\"August max (F)\"] = pd.to_numeric(txinfo[\"August max (F)\"])\n",
    "txinfo[\"August min (F)\"] = pd.to_numeric(txinfo[\"August min (F)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1 Find the city with the max January daily temperature\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brownsville'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"4.1 Find the city with the max January daily temperature\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "txinfo.loc[txinfo['January max (F)'].idxmax()]['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 Find the city with the min January daily temperature\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amarillo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"4.2 Find the city with the min January daily temperature\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "txinfo.loc[txinfo['January min (F)'].idxmin()]['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3 Find the city with the max August daily temperature\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Laredo'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"4.3 Find the city with the max August daily temperature\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "txinfo.loc[txinfo['August max (F)'].idxmax()]['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4 Find the city with the min August daily temperature\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amarillo'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"4.4 Find the city with the min August daily temperature\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "txinfo.loc[txinfo['August min (F)'].idxmin()]['Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check your work above\n",
    "\n",
    "If you didn't get them all correct, take a few minutes to think through those that aren't correct.\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Are you ready to submit your work?\n",
      "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
      "2. Type \"yes\" or \"no\" below\n",
      "3. Press Enter\n",
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3380c47] Submitting the week 7 programming exercises\n",
      " 2 files changed, 804 insertions(+), 2 deletions(-)\n",
      " create mode 100644 week07/week07_assignment_2.ipynb\n",
      "Counting objects: 5, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 7.41 KiB | 1.48 MiB/s, done.\n",
      "Total 5 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To github.com:rasalt/hds5210-2022.git\n",
      "   6542e21..3380c47  main -> main\n"
     ]
    }
   ],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git add week07_assignment_2.ipynb\n",
    "    !git commit -a -m \"Submitting the week 7 programming exercises\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
